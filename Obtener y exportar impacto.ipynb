{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd21f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import olca_ipc as ipc\n",
    "import olca_schema as schema\n",
    "\n",
    "client = ipc.Client(8080)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivo donde guardaremos los procesos\n",
    "FILE_PATH = \"process_descriptors.txt\"\n",
    "\n",
    "# Leer los IDs ya guardados (si el archivo existe)\n",
    "try:\n",
    "    with open(FILE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        saved_ids = {line.split(\"\\t\")[0] for line in f if line.strip()}\n",
    "except FileNotFoundError:\n",
    "    saved_ids = set()\n",
    "\n",
    "print(f\"Ya tienes {len(saved_ids)} procesos guardados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37e5454",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = client.get_descriptors(schema.Process)\n",
    "\n",
    "# Contar cuántos hay\n",
    "total_procesos = len(descriptors)\n",
    "print(f\"Total de procesos en la base: {total_procesos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f762f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    " 3. Reanudar desde los que faltan\n",
    "with open(FILE_PATH, \"a\", encoding=\"utf-8\") as f:\n",
    "    for i, d in enumerate(descriptors, start=1):\n",
    "        if d.id in saved_ids:\n",
    "            continue  \n",
    "        try:\n",
    "            proceso = client.get(schema.Process, d.id)\n",
    "            f.write(f\"{proceso.id}\\t{proceso.name}\\t{proceso.category}\\n\")\n",
    "            saved_ids.add(proceso.id)\n",
    "\n",
    "            if len(saved_ids) % 100 == 0:\n",
    "                print(f\"Van {len(saved_ids)} procesos guardados...\")\n",
    "        except Exception as e:\n",
    "            print(f\" Error en {d.id}: {e}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a54df",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"process_descriptors.txt\"  \n",
    "df = pd.read_csv(FILE_PATH, sep=\"\\t\", names=[\"id\", \"name\", \"category\"], header=None)\n",
    "prefijo = \"H:Transportation and storage\" #Cambiar el nombre ###No quitar el \":\"\n",
    "filtered = df[df[\"category\"].str.startswith(prefijo, na=False)]\n",
    "\n",
    "\n",
    "_process_ids = filtered[\"id\"].tolist()\n",
    "\n",
    "print(f\"Se encontraron {len(_process_ids)} procesos bajo la categoría {prefijo}\")\n",
    "print(_process_ids[:5])  # muestra solo los primeros 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a82385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "impact_data = []\n",
    "\n",
    "# Archivos de salida\n",
    "FILE_PATH = \"H Transportation and storage.jsonl\"   # resultados ##Cambiar el nombre ##Quitar \":\"\n",
    "CHECKPOINT_FILE = \"checkpoint.txt\"   # último proceso exitoso ##Borarr el documento al empezar un nuevo documento\n",
    "ERROR_FILE = \"errores.txt\"           # log de errores ##Borrar el documento al empezar una nueva carpeta\n",
    "\n",
    "impact_method_ref = client.get_descriptor(\n",
    "    schema.ImpactMethod,\n",
    "    '61966689-76aa-4b3b-94f1-81989199433f'\n",
    ")\n",
    "\n",
    "#  Leer checkpoint si existe\n",
    "start_index = 0\n",
    "if os.path.exists(CHECKPOINT_FILE):\n",
    "    with open(CHECKPOINT_FILE, \"r\") as f:\n",
    "        try:\n",
    "            start_index = int(f.read().strip())\n",
    "        except:\n",
    "            start_index = 0\n",
    "\n",
    "print(f\" Retomando desde el índice {start_index}\")\n",
    "\n",
    "# Iterar sobre los procesos\n",
    "for idx, process_id in enumerate(_process_ids[start_index:], start=start_index):\n",
    "    try:\n",
    "        process_ref = client.get_descriptor(schema.Process, process_id)\n",
    "\n",
    "        # Configurar el sistema de producto\n",
    "        config = schema.LinkingConfig(\n",
    "            prefer_unit_processes=True,\n",
    "            provider_linking=schema.ProviderLinking.ONLY_DEFAULTS\n",
    "        )\n",
    "        product_system_ref = client.create_product_system(process_ref, config)\n",
    "\n",
    "        # Configurar el cálculo\n",
    "        setup = schema.CalculationSetup(\n",
    "            target=product_system_ref,\n",
    "            impact_method=impact_method_ref\n",
    "        )\n",
    "        result = client.calculate(setup)\n",
    "        state = result.wait_until_ready()\n",
    "\n",
    "        # Guardar resultados en JSONL (línea por línea)\n",
    "        with open(FILE_PATH, \"a\", encoding=\"utf-8\") as f:\n",
    "            for impact in result.get_total_impacts():\n",
    "                record = {\n",
    "                    \"Name\": process_ref.name,\n",
    "                    \"Category\": impact.impact_category.name,\n",
    "                    \"Unit\": impact.impact_category.ref_unit,\n",
    "                    \"Amount\": impact.amount,\n",
    "                    \"ubi\": process_ref.location,\n",
    "                    \"id\": process_id\n",
    "                }\n",
    "                f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "        result.dispose()\n",
    "        client.delete(product_system_ref)\n",
    "\n",
    "        # Guardar progreso en el checkpoint\n",
    "        with open(CHECKPOINT_FILE, \"w\") as f:\n",
    "            f.write(str(idx + 1))\n",
    "\n",
    "    except Exception as e:\n",
    "        # Guardar errores para revisar después\n",
    "        with open(ERROR_FILE, \"a\", encoding=\"utf-8\") as ef:\n",
    "            ef.write(f\"Error en proceso {process_id} (índice {idx}): {str(e)}\\n\")\n",
    "        print(f\" Error en proceso {process_id}, registrado en {ERROR_FILE}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb11a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar JSONL a DataFrame\n",
    "df = pd.read_json(\"H Transportation and storage.jsonl\", lines=True, encoding=\"utf-8\")\n",
    "\n",
    "# Ver las primeras filas\n",
    "#print(df.head())\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d4ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivotear\n",
    "final_df = df.pivot_table(\n",
    "    index=[\"Name\", \"id\", \"ubi\"],   \n",
    "    columns=\"Category\",\n",
    "    values=\"Amount\",\n",
    "    aggfunc=\"sum\",\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "print(final_df)\n",
    "# Exportar a Excel\n",
    "final_df.to_excel(\"H Transportation and storage.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
